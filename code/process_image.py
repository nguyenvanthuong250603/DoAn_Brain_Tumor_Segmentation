import streamlit as st
import numpy as np
import torch
import cv2
from PIL import Image

# Th∆∞ vi·ªán cho 3D Visualization
import plotly.graph_objects as go
from skimage import measure

# ============================================================================
# 1. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH & TI·ªÜN √çCH
# ============================================================================
SEGMENT_CLASSES = {
    0: "Background",
    1: "Necrotic/Core (L√µi ho·∫°i t·ª≠)",
    2: "Edema (Ph√π n·ªÅ)",
    3: "Enhancing (U b·∫Øt thu·ªëc)",
}

CLASS_COLORS = {
    0: (0, 0, 0),  # ƒêen
    1: (255, 50, 50),  # ƒê·ªè
    2: (50, 255, 50),  # Xanh l√°
    3: (50, 50, 255),  # Xanh d∆∞∆°ng
}
TARGET_SIZE = 240
PIXEL_TO_MM3 = 1.0  # Gi·∫£ ƒë·ªãnh 1 voxel = 1mm3 (C·∫ßn ch·ªânh n·∫øu c√≥ header file g·ªëc)


def zscore_normalization(volume):
    """Chu·∫©n h√≥a ·∫£nh ƒë·ªÉ model d·ªÖ h·ªçc"""
    mean = np.mean(volume)
    std = np.std(volume)
    if std < 1e-8:
        return np.zeros_like(volume)
    return (volume - mean) / std


def clean_segmentation_3d(mask_3d):
    """
    üßπ H√ÄM L·ªåC R√ÅC QUAN TR·ªåNG:
    Ch·ªâ gi·ªØ l·∫°i kh·ªëi u li√™n th√¥ng l·ªõn nh·∫•t (Largest Connected Component).
    X√≥a b·ªè c√°c ƒë·ªëm nhi·ªÖu nh·ªè li ti do model d·ª± ƒëo√°n sai.
    """
    # T·∫°o mask nh·ªã ph√¢n: Ch·ªó n√†o l√† u (b·∫•t k·ªÉ lo·∫°i 1,2,3) th√¨ = 1, n·ªÅn = 0
    binary_mask = mask_3d > 0

    # T√¨m c√°c kh·ªëi li√™n th√¥ng trong kh√¥ng gian 3D
    labels = measure.label(binary_mask)

    # N·∫øu kh√¥ng t√¨m th·∫•y kh·ªëi u n√†o
    if labels.max() == 0:
        return mask_3d

    # T√≠nh th·ªÉ t√≠ch t·ª´ng kh·ªëi (ƒë·∫øm s·ªë pixel c·ªßa t·ª´ng label)
    regions = measure.regionprops(labels)

    # T√¨m kh·ªëi c√≥ di·ªán t√≠ch l·ªõn nh·∫•t
    largest_region = max(regions, key=lambda r: r.area)

    # T·∫°o mask s·∫°ch: Ch·ªâ gi·ªØ l·∫°i v·ªã tr√≠ c·ªßa kh·ªëi l·ªõn nh·∫•t
    # Nh√¢n v·ªõi mask g·ªëc ƒë·ªÉ ph·ª•c h·ªìi l·∫°i c√°c nh√£n 1, 2, 3
    cleaned_mask = mask_3d * (labels == largest_region.label)

    return cleaned_mask


def calculate_tumor_volume_slice(pred_mask):
    unique, counts = np.unique(pred_mask, return_counts=True)
    stats = dict(zip(unique, counts))
    return {
        "NCR": stats.get(1, 0) * PIXEL_TO_MM3,
        "ED": stats.get(2, 0) * PIXEL_TO_MM3,
        "ET": stats.get(3, 0) * PIXEL_TO_MM3,
        "TOTAL": (stats.get(1, 0) + stats.get(2, 0) + stats.get(3, 0)) * PIXEL_TO_MM3,
    }


def create_color_mask(pred_mask):
    h, w = pred_mask.shape
    color_img = np.zeros((h, w, 3), dtype=np.uint8)
    for cid, color in CLASS_COLORS.items():
        if cid == 0:
            continue
        color_img[pred_mask == cid] = color
    return color_img


def create_overlay(bg_img, mask_img, alpha=0.4):
    bg_norm = cv2.normalize(bg_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    bg_rgb = cv2.cvtColor(bg_norm, cv2.COLOR_GRAY2RGB)
    if bg_rgb.shape[:2] != mask_img.shape[:2]:
        mask_img = cv2.resize(
            mask_img,
            (bg_rgb.shape[1], bg_rgb.shape[0]),
            interpolation=cv2.INTER_NEAREST,
        )
    return Image.fromarray(cv2.addWeighted(bg_rgb, 1 - alpha, mask_img, alpha, 0))


# ============================================================================
# 2. H√ÄM D·ª∞ ƒêO√ÅN & D·ª∞NG H√åNH 3D
# ============================================================================
def predict_whole_volume(model, device, vol_data, batch_size=16):
    """
    D·ª± ƒëo√°n to√†n b·ªô volume 3D v·ªõi c∆° ch·∫ø AN TO√ÄN:
    1. B·ªè qua c√°c l√°t ƒë·∫ßu/cu·ªëi (th∆∞·ªùng g√¢y nhi·ªÖu).
    2. Ch·ªâ gi·ªØ l·∫°i d·ª± ƒëo√°n n·∫øu v√πng ƒë√≥ th·ª±c s·ª± c√≥ n√£o (d·ª±a tr√™n ·∫£nh T1).
    """
    depth = vol_data["flair"].shape[-1]

    # Kh·ªüi t·∫°o m·∫£ng 3D
    full_mask_3d = np.zeros((TARGET_SIZE, TARGET_SIZE, depth), dtype=np.uint8)
    full_brain_3d = np.zeros((TARGET_SIZE, TARGET_SIZE, depth), dtype=np.float32)

    progress_bar = st.progress(0)
    status_text = st.empty()
    model.eval()

    # --- C·∫§U H√åNH AN TO√ÄN ---
    SKIP_SLICES = 15  # B·ªè qua 15 l√°t ƒë·∫ßu v√† 15 l√°t cu·ªëi ƒë·ªÉ tr√°nh l·ªói "t·∫•m th·ªõt ƒë·ªè"

    # --- B∆Ø·ªöC 1: D·ª∞ ƒêO√ÅN T·ª™NG BATCH ---
    for i in range(0, depth, batch_size):
        end = min(i + batch_size, depth)
        batch_frames = []
        valid_indices = []  # L∆∞u l·∫°i index c·ªßa c√°c l√°t h·ª£p l·ªá ƒë·ªÉ g√°n l·∫°i sau

        # Chu·∫©n b·ªã batch
        for idx in range(i, end):
            # L∆∞u T1 g·ªëc ƒë·ªÉ v·∫Ω n√£o
            t1_original = cv2.resize(
                vol_data["t1"][:, :, idx], (TARGET_SIZE, TARGET_SIZE)
            )
            full_brain_3d[:, :, idx] = t1_original

            # üõ†Ô∏è FIX 1: N·∫øu l√† l√°t ƒë·∫ßu ho·∫∑c l√°t cu·ªëi -> B·ªè qua, kh√¥ng d·ª± ƒëo√°n
            if idx < SKIP_SLICES or idx > (depth - SKIP_SLICES):
                continue

            # üõ†Ô∏è FIX 2: N·∫øu ·∫£nh qu√° t·ªëi (kh√¥ng c√≥ n√£o) -> B·ªè qua
            if np.max(t1_original) < 0.01:
                continue

            # Chu·∫©n h√≥a v√† ƒë∆∞a v√†o batch
            s_flair = zscore_normalization(
                cv2.resize(vol_data["flair"][:, :, idx], (TARGET_SIZE, TARGET_SIZE))
            )
            s_t1 = zscore_normalization(t1_original)  # ƒê√£ resize ·ªü tr√™n
            s_t1ce = zscore_normalization(
                cv2.resize(vol_data["t1ce"][:, :, idx], (TARGET_SIZE, TARGET_SIZE))
            )
            s_t2 = zscore_normalization(
                cv2.resize(vol_data["t2"][:, :, idx], (TARGET_SIZE, TARGET_SIZE))
            )

            stack = np.stack([s_flair, s_t1, s_t1ce, s_t2], axis=0).astype(np.float32)
            batch_frames.append(stack)
            valid_indices.append(idx)

        if not batch_frames:
            continue

        # ƒê∆∞a v√†o model
        batch_tensor = torch.from_numpy(np.array(batch_frames)).to(device)
        with torch.no_grad():
            output = model(batch_tensor)
            preds = torch.argmax(output, dim=1).cpu().numpy()  # (Batch, H, W)

        # L∆∞u k·∫øt qu·∫£ v√†o m·∫£ng 3D (Ch·ªâ l∆∞u v√†o ƒë√∫ng v·ªã tr√≠ valid)
        for k, p in enumerate(preds):
            real_idx = valid_indices[k]

            # üõ†Ô∏è FIX 3: MASKING (Quan tr·ªçng nh·∫•t)
            # Ch·ªâ ch·∫•p nh·∫≠n kh·ªëi u n·∫øu t·∫°i ƒë√≥ ·∫£nh n√£o (T1) kh√¥ng ph·∫£i m√†u ƒëen
            # ƒêi·ªÅu n√†y x√≥a s·ªï ho√†n to√†n l·ªói d·ª± ƒëo√°n u bay l∆° l·ª≠ng ngo√†i h·ªôp s·ªç
            brain_mask = full_brain_3d[:, :, real_idx] > 0.1  # Ng∆∞·ª°ng nh·∫π ƒë·ªÉ t√°ch n·ªÅn

            # G√°n k·∫øt qu·∫£ ƒë√£ l·ªçc v√†o mask 3D
            full_mask_3d[:, :, real_idx] = p * brain_mask.astype(np.uint8)

        progress_bar.progress(min(end / depth, 1.0))
        status_text.text(f"ƒêang d·ª± ƒëo√°n layer: {end}/{depth}")

    # --- B∆Ø·ªöC 2: H·∫¨U X·ª¨ L√ù (L·ªåC NHI·ªÑU) ---
    status_text.text("ƒêang l·ªçc nhi·ªÖu 3D...")
    clean_mask_3d = clean_segmentation_3d(full_mask_3d)

    # --- B∆Ø·ªöC 3: T√çNH TO√ÅN TH·ªÇ T√çCH ---
    total_mm3 = {"NCR": 0.0, "ED": 0.0, "ET": 0.0, "TOTAL": 0.0}
    unique, counts = np.unique(clean_mask_3d, return_counts=True)
    stats_all = dict(zip(unique, counts))

    total_mm3["NCR"] = stats_all.get(1, 0) * PIXEL_TO_MM3
    total_mm3["ED"] = stats_all.get(2, 0) * PIXEL_TO_MM3
    total_mm3["ET"] = stats_all.get(3, 0) * PIXEL_TO_MM3
    total_mm3["TOTAL"] = sum(total_mm3.values())

    status_text.empty()
    progress_bar.empty()

    final_stats = {k: v / 1000.0 for k, v in total_mm3.items()}
    return final_stats, clean_mask_3d, full_brain_3d


def plot_3d_tumor(volume_mask, brain_volume):
    """
    V·∫Ω n√£o b·ªô trong su·ªët v√† kh·ªëi u b√™n trong
    """
    fig = go.Figure()

    # 1. V·∫º V·ªé N√ÉO (D√πng d·ªØ li·ªáu T1)
    try:
        brain_norm = (brain_volume - brain_volume.min()) / (
            brain_volume.max() - brain_volume.min()
        )

        # step_size=2: Gi√∫p render nhanh h∆°n v√† l√†m m∆∞·ª£t b·ªÅ m·∫∑t
        verts_b, faces_b, _, _ = measure.marching_cubes(
            brain_norm, level=0.15, step_size=2
        )

        fig.add_trace(
            go.Mesh3d(
                x=verts_b[:, 0],
                y=verts_b[:, 1],
                z=verts_b[:, 2],
                i=faces_b[:, 0],
                j=faces_b[:, 1],
                k=faces_b[:, 2],
                opacity=0.08,  # R·∫•t trong su·ªët
                color="lightgray",
                name="C·∫•u tr√∫c N√£o",
                showlegend=True,
                hoverinfo="skip",
            )
        )
    except Exception as e:
        print(f"Kh√¥ng th·ªÉ v·∫Ω v·ªè n√£o (c√≥ th·ªÉ do n·ªÅn ƒëen qu√° nhi·ªÅu): {e}")

    # 2. V·∫º KH·ªêI U (D√πng mask d·ª± ƒëo√°n)
    classes = [
        (1, "L√µi Ho·∫°i t·ª≠ (NCR)", "red", 1.0),
        (3, "U B·∫Øt thu·ªëc (ET)", "blue", 0.5),
        (2, "Ph√π n·ªÅ (ED)", "green", 0.15),
    ]

    has_tumor = False
    for class_id, name, color, opacity in classes:
        mask = volume_mask == class_id
        if not np.any(mask):
            continue

        try:
            # step_size=1 ho·∫∑c 2 ƒë·ªÉ kh·ªëi u chi ti·∫øt h∆°n v·ªè n√£o
            verts, faces, _, _ = measure.marching_cubes(mask, level=0.5, step_size=1)

            fig.add_trace(
                go.Mesh3d(
                    x=verts[:, 0],
                    y=verts[:, 1],
                    z=verts[:, 2],
                    i=faces[:, 0],
                    j=faces[:, 1],
                    k=faces[:, 2],
                    opacity=opacity,
                    color=color,
                    name=name,
                    showlegend=True,
                )
            )
            has_tumor = True
        except Exception:
            continue

    if not has_tumor:
        return None

    # C·∫•u h√¨nh Camera v√† √Ånh s√°ng
    fig.update_layout(
        scene=dict(
            xaxis=dict(visible=False, backgroundcolor="black"),
            yaxis=dict(visible=False, backgroundcolor="black"),
            zaxis=dict(visible=False, backgroundcolor="black"),
            aspectmode="data",
            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),
        ),
        title="M√¥ h√¨nh N√£o 3D & Kh·ªëi u (ƒê√£ l·ªçc nhi·ªÖu)",
        margin=dict(l=0, r=0, b=0, t=40),
        legend=dict(x=0, y=1, font=dict(color="white")),
        paper_bgcolor="black",
    )
    return fig


def norm_show(img):
    """
    H√†m ph·ª• tr·ª£: Chu·∫©n h√≥a ·∫£nh v·ªÅ kho·∫£ng [0, 255] v√† √©p ki·ªÉu sang uint8
    ƒë·ªÉ hi·ªÉn th·ªã ƒë∆∞·ª£c tr√™n Streamlit/Matplotlib.
    """
    # Tr√°nh l·ªói chia cho 0 ho·∫∑c ·∫£nh r·ªóng
    if img is None or img.size == 0:
        return np.zeros((100, 100), dtype=np.uint8)

    # Min-max scaling v·ªÅ 0-255
    img_norm = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)

    # √âp ki·ªÉu th√†nh s·ªë nguy√™n 8-bit (uint8)
    return img_norm.astype(np.uint8)
